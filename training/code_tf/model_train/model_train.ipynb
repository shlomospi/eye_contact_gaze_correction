{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mmnet\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agl_dim=2, batch_size=256, channel=3, data_dir='../../dataset/', dataset='dirl_48x64_example', early_stop=16, easy_mode=True, ef_dim=12, encoded_agl_dim=16, epochs=500, eye='L', height=48, load_weights=False, loss_combination='l2sc', lr=0.001, tar_model='flx', tb_dir='TFboard/', train_dir='training_inputs/', valid_dir='valid_inputs/', weight_dir='pt_ckpt/', width=64)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformation\n",
    "import load_dataset2\n",
    "import config\n",
    "\n",
    "conf,_ = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Type is l2sc\n"
     ]
    }
   ],
   "source": [
    "if conf.tar_model == \"flx\":\n",
    "    import flx as model\n",
    "else:\n",
    "    sys.exit(\"Sorry, Wrong Model!\")\n",
    "# tar_model='deepwarp'\n",
    "if conf.loss_combination == 'l2sc' or conf.loss_combination == 'l2s' or conf.loss_combination == 'l2':\n",
    "    print ('Loss Type is', conf.loss_combination)\n",
    "else:\n",
    "    sys.exit(\"Sorry, Wrong Loss Combination!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters, folders, and #GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(711129)\n",
    "'''setting'''\n",
    "gpus = [0,1] # Here I set CUDA to only see one GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(i) for i in gpus])\n",
    "n_gpus = len(gpus) # number of GPUs to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions from TF (Do not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "        is over individual gradients. The inner list is over the gradient\n",
    "        calculation for each tower.\n",
    "    Returns:\n",
    "       List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "       across all towers.\n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    \n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "      # Note that each grad_and_vars looks like the following:\n",
    "      #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        \n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tower Loss (define your model here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tower_loss(scope, input_img, input_fp, input_ang, img_, phase_train, eye_mask, loss_combination):\n",
    "    # model\n",
    "    img_pred, flow, lcm_wgts,_ = model.inference(input_img, input_fp, input_ang, phase_train, conf)\n",
    "    \n",
    "    # calcuate loss\n",
    "    with tf.name_scope('loss'):\n",
    "        _, l2_loss = model.loss(img_pred, img_, eye_mask, input_img, flow, lcm_wgts, loss_combination)\n",
    "        \n",
    "    losses = tf.get_collection('losses', scope)\n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "    return total_loss, img_pred, flow, lcm_wgts, l2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tower_0\n",
      "tower_1\n",
      "total_parameters 249328\n"
     ]
    }
   ],
   "source": [
    "TOWER_NAME = 'tower'\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    # define step counter\n",
    "    global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "    # define lr and bn control\n",
    "    with tf.name_scope('model_control'):\n",
    "        phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    # define inputs\n",
    "    with tf.name_scope('inputs'):\n",
    "        input_img = tf.placeholder(tf.float32, [None, conf.height, conf.width, conf.channel], name='input_img') # [None, 41, 51, 3]\n",
    "        input_fp = tf.placeholder(tf.float32, [None, conf.height, conf.width,conf.ef_dim], name='input_fp') # [None, 41, 51, 14]\n",
    "        input_ang = tf.placeholder(tf.float32, [None, conf.agl_dim], name='input_ang') ## [None, 2]        \n",
    "        img_ = tf.placeholder(tf.float32, [None, conf.height, conf.width, conf.channel], name ='Ground_Truth') # [None, 41, 51, 3]\n",
    "        input_eye_msk = tf.placeholder(tf.float32, [None, conf.height, conf.width], name='input_eye_msk') # [None, 41, 51]\n",
    "\n",
    "    # define optimizer\n",
    "    opt = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "    \n",
    "    # define Tower\n",
    "    tower_grads = []\n",
    "    tower_synImgs = []\n",
    "    tower_CM = []\n",
    "    tower_Tloss=[]\n",
    "    tower_L2loss=[]\n",
    "    with tf.variable_scope('gen'):\n",
    "        for i in xrange(n_gpus):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('%s_%d' % (TOWER_NAME, i)) as scope:\n",
    "                    print('%s_%d' % (TOWER_NAME, i))\n",
    "                    Tloss, synImgs, _, ss_CM, L2loss = tower_loss(scope,\n",
    "                                                                input_img[i*conf.batch_size:(i+1)*conf.batch_size],\n",
    "                                                                input_fp[i*conf.batch_size:(i+1)*conf.batch_size],\n",
    "                                                                input_ang[i*conf.batch_size:(i+1)*conf.batch_size],\n",
    "                                                                img_[i*conf.batch_size:(i+1)*conf.batch_size],                                 \n",
    "                                                                phase_train,\n",
    "                                                                input_eye_msk[i*conf.batch_size:(i+1)*conf.batch_size],\n",
    "                                                                conf.loss_combination)\n",
    "                    # Reuse variables for the next tower.\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    \n",
    "                    # get generator parameter list\n",
    "                    gen_vars = [var for var in tf.trainable_variables() if var.name.startswith(\"gen\")] #; print(gen_vars)\n",
    "\n",
    "                    # Calculate the gradients for the batch of data on this tower.\n",
    "                    grads = opt.compute_gradients(Tloss, var_list=gen_vars)\n",
    "                    # Keep track of the gradients across all towers.\n",
    "                    tower_grads.append(grads)\n",
    "                    tower_synImgs.append(synImgs)\n",
    "                    tower_CM.append(ss_CM)\n",
    "                    tower_Tloss.append(Tloss)\n",
    "                    tower_L2loss.append(L2loss)\n",
    "\n",
    "        gen_grads = average_gradients(tower_grads)\n",
    "        pred_synImgs = tf.reshape(tower_synImgs, shape = [n_gpus*conf.batch_size, conf.height, conf.width,3])\n",
    "        pred_CM = tf.reshape(tower_CM, shape = [n_gpus*conf.batch_size, conf.height, conf.width,2])\n",
    "        pred_Tloss = tf.reshape(tower_Tloss, shape = [n_gpus])\n",
    "        pred_L2loss = tf.reshape(tower_L2loss, shape = [n_gpus])\n",
    "\n",
    "    # apply gradient to weights\n",
    "    apply_gradient_op = opt.apply_gradients(gen_grads, global_step=global_step)\n",
    "\n",
    "    # weight init\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Create a saver\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    saver2 = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    # define tf.sess\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "\n",
    "    # define graph writer\n",
    "    writer = tf.summary.FileWriter(conf.tb_dir, graph = sess.graph)\n",
    "    \n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "\n",
    "        total_parameters += variable_parameters\n",
    "    print('total_parameters', total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training & validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose dirs ['0']\n",
      "pose 0\n",
      "Dirs ['0000' '0001' '0002']\n",
      "../../dataset/dirl_48x64_example\\training_inputs/0\\0000\n",
      "../../dataset/dirl_48x64_example\\training_inputs/0\\0001\n",
      "../../dataset/dirl_48x64_example\\training_inputs/0\\0002\n",
      "Pose dirs ['0']\n",
      "pose 0\n",
      "Dirs ['0008']\n",
      "../../dataset/dirl_48x64_example\\valid_inputs/0\\0008\n"
     ]
    }
   ],
   "source": [
    "train_dicts = load_dataset2.get_dict(conf, 'training_inputs/')\n",
    "valid_dicts = load_dataset2.get_dict(conf, 'valid_inputs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 3219; H 26186; ALL 29405\n",
      "E 1010; H 8990; ALL 10000\n"
     ]
    }
   ],
   "source": [
    "train_iter_ = load_dataset2.get_easy_hard_iter(train_dicts, int(n_gpus*conf.batch_size/4))\n",
    "valid_iter_ = load_dataset2.get_easy_hard_iter(valid_dicts, int(n_gpus*conf.batch_size/4))\n",
    "# [0] easy iter, [1] hard iter, [2] #pair of easy iter, [3] #pair of hard iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(ckpt_dir, valid_batch, valid_synImg, valid_CM, n_epoch):\n",
    "    fig_per_loop = 5\n",
    "    img_per_row = 5\n",
    "    for i in range(fig_per_loop):\n",
    "        plt.subplot(fig_per_loop, img_per_row, fig_per_loop*i+1)\n",
    "        plt.imshow(np.asarray(valid_batch['imgs_ori'])[fig_per_loop + i,...])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(fig_per_loop, img_per_row, fig_per_loop*i+2)\n",
    "        plt.imshow(np.asarray(valid_batch['imgs__ori'])[fig_per_loop + i,...])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(fig_per_loop, img_per_row, fig_per_loop*i+3)\n",
    "        plt.imshow(np.asarray(valid_synImg)[fig_per_loop + i,...])\n",
    "        plt.axis('off')\n",
    "\n",
    "        dif_img = np.absolute(np.asarray(valid_synImg)[fig_per_loop + i,...]-np.asarray(valid_batch['imgs__ori'])[fig_per_loop + i,...])\n",
    "        dif_img_gray = np.sum(dif_img,axis =2)\n",
    "        plt.subplot(fig_per_loop, img_per_row, fig_per_loop*i+4)\n",
    "        plt.imshow(dif_img_gray, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(fig_per_loop, img_per_row, fig_per_loop*i+5)\n",
    "        plt.imshow(np.asarray(valid_CM)[fig_per_loop + i,...,1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(ckpt_dir+'imgs/'+'/imgs-'+str(n_epoch)+'.png')\n",
    "#     plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(conf, ckpt_dir, train_iter_, valid_iter_, easy_mode=True, load_weights=True):\n",
    "    # load modeling if we want\n",
    "    if (load_weights):\n",
    "        ckpt = tf.train.get_checkpoint_state(conf.weight_dir+conf.tar_model+'_'+conf.loss_combination+'/'+str(conf.ef_dim)+'/'+conf.eye+'/')\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            if (easy_mode):\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                saver2.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            print('Loading sucessfully')\n",
    "        else:\n",
    "            print('No checkpoint file found')\n",
    "            raise\n",
    "    else:\n",
    "        sess.run(init)\n",
    "        \n",
    "    if not os.path.exists(ckpt_dir+'imgs/'):\n",
    "        os.makedirs(ckpt_dir+'imgs/') \n",
    "    \n",
    "    # define init. constants for training\n",
    "    stop_counter = 0\n",
    "    min_Tloss = 9999\n",
    "    min_L2loss = 9999\n",
    "    learning_decay_count = 0\n",
    "    cur_lr = conf.lr\n",
    "    \n",
    "    # prepare monitoring .csv file\n",
    "    fout= open(ckpt_dir+conf.loss_combination+'_'+conf.dataset+'_'+conf.eye+'.csv', 'w')\n",
    "    if not os.path.exists(ckpt_dir+'imgs/'):\n",
    "        os.makedirs(ckpt_dir+'imgs/')\n",
    "\n",
    "    fout.write(str('step,train_loss,valid_loss,img_diff,hard_valid_loss,hard_img_diff \\n'))         \n",
    "\n",
    "    if (easy_mode):\n",
    "        step_per_epoch = int(train_iter_[2]/(n_gpus*conf.batch_size))\n",
    "    else:\n",
    "        step_per_epoch = int(4*train_iter_[3]/(n_gpus*conf.batch_size))\n",
    "        \n",
    "    for n_epoch in range(conf.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print('------%d/%d------' % (n_epoch, conf.epochs))\n",
    "        steps = 0\n",
    "\n",
    "        # training step\n",
    "        for s in range(step_per_epoch):\n",
    "            batch_start_time = time.time()            \n",
    "            steps = (n_epoch*step_per_epoch + s)\n",
    "\n",
    "            # ------- start validation -------\n",
    "            if (steps % int(step_per_epoch/2) == 0):\n",
    "                # for a validation epoch\n",
    "                valid_easy_Tlosses = []\n",
    "                valid_easy_L2losses = []\n",
    "                valid_hard_Tlosses = []\n",
    "                valid_hard_L2losses = []\n",
    "\n",
    "                # hard part\n",
    "                for s in range(int(valid_iter_[3]/(n_gpus*conf.batch_size))):\n",
    "                    # get 4 sub_batch from hard iter\n",
    "                    temp_batch = next(valid_iter_[1])\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[1]))\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[1]))\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[1]))\n",
    "                    valid_batch = load_dataset2.shuffle_data_batch(temp_batch)\n",
    "\n",
    "                    valid_synImg, valid_CM, valid_Tloss, valid_L2loss = sess.run([pred_synImgs, pred_CM, pred_Tloss, pred_L2loss],\n",
    "                                                                                  feed_dict={                                                                  \n",
    "                                                                                      input_img: valid_batch['imgs_ori'],\n",
    "                                                                                      input_fp: valid_batch['fp'][:,:,:,0:conf.ef_dim],\n",
    "                                                                                      input_ang: valid_batch['tar_agl']-valid_batch['sur_agl'],\n",
    "                                                                                      img_: valid_batch['imgs__ori'],\n",
    "                                                                                      learning_rate: cur_lr,\n",
    "                                                                                      phase_train: False,\n",
    "                                                                                      input_eye_msk: valid_batch['msk_eye']\n",
    "                                                                                  })\n",
    "                    valid_hard_Tlosses.append(valid_Tloss)\n",
    "                    valid_hard_L2losses.append(valid_L2loss)\n",
    "\n",
    "                # easy part\n",
    "                for s in range(int(valid_iter_[2]/(n_gpus*conf.batch_size))):\n",
    "                    # get 4 sub_batch from easy iter\n",
    "                    temp_batch = next(valid_iter_[0])\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[0]))\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[0]))\n",
    "                    temp_batch = load_dataset2.merge_batches(temp_batch,next(valid_iter_[0]))\n",
    "                    valid_batch = load_dataset2.shuffle_data_batch(temp_batch)\n",
    "\n",
    "                    valid_synImg, valid_CM, valid_Tloss, valid_L2loss = sess.run([pred_synImgs, pred_CM, pred_Tloss, pred_L2loss],\n",
    "                                                                                  feed_dict={                                                                  \n",
    "                                                                                      input_img: valid_batch['imgs_ori'],\n",
    "                                                                                      input_fp: valid_batch['fp'][:,:,:,0:conf.ef_dim],\n",
    "                                                                                      input_ang: valid_batch['tar_agl']-valid_batch['sur_agl'],\n",
    "                                                                                      img_: valid_batch['imgs__ori'],\n",
    "                                                                                      learning_rate: cur_lr,\n",
    "                                                                                      phase_train: False,\n",
    "                                                                                      input_eye_msk: valid_batch['msk_eye']\n",
    "                                                                                  })\n",
    "                    valid_easy_Tlosses.append(valid_Tloss)\n",
    "                    valid_easy_L2losses.append(valid_L2loss)\n",
    "\n",
    "                VeT = np.mean(valid_easy_Tlosses)\n",
    "                VeL2 = np.mean(valid_easy_L2losses)\n",
    "                VhT = np.mean(valid_hard_Tlosses)\n",
    "                VhL2 = np.mean(valid_hard_L2losses)\n",
    "\n",
    "                fout.write(str('%d,NA,%.4f,%.4f,%.4f,%.4f\\n' % (steps, VeT, VeL2, VhT, VhL2)))\n",
    "                fout.flush()\n",
    "\n",
    "                # show some validation synthesized images\n",
    "                print_result(ckpt_dir, valid_batch, valid_synImg, valid_CM,n_epoch)\n",
    "               \n",
    "                # early stop based on the validation results\n",
    "                if((VeT < min_Tloss) or (VeL2 < min_L2loss)):\n",
    "                    if (VeT < min_Tloss):\n",
    "                        min_Tloss = VeT\n",
    "                    if (VeL2 < min_L2loss):\n",
    "                        min_L2loss = VeL2\n",
    "                    stop_counter = 0\n",
    "                    print('-- Step %d, [V*] eT=%.1f, eL2=%.1f; hT=%.1f, hL2=%.1f' % (steps, VeT, VeL2, VhT, VhL2))\n",
    "\n",
    "                    if(easy_mode):\n",
    "                        saver.save(sess, ckpt_dir+conf.dataset+'_'+conf.eye+str(n_epoch), global_step)\n",
    "                    else:\n",
    "                        saver2.save(sess, ckpt_dir+conf.dataset+'_'+conf.eye+str(n_epoch), global_step)\n",
    "                else:\n",
    "                    stop_counter = stop_counter +1\n",
    "                    print('-- Step %d, [V] eT=%.1f, eL2=%.1f; hT=%.1f, hL2=%.1f' % (steps, VeT, VeL2, VhT, VhL2))\n",
    "                    if (stop_counter % np.floor(conf.early_stop / 3) == 0):\n",
    "                        learning_decay_count = learning_decay_count + 1\n",
    "                        cur_lr = conf.lr * np.power(0.9, learning_decay_count)\n",
    "                        print('Decreasing lr to %f' % cur_lr)\n",
    "                        \n",
    "                    # break step\n",
    "                    if (stop_counter > conf.early_stop):\n",
    "                        print('Early stop at step %d' % steps)\n",
    "                        \n",
    "                        break\n",
    "\n",
    "            # ------- start training -------\n",
    "            # get batch\n",
    "            temp_batch = next(train_iter_[0])\n",
    "            temp_batch = load_dataset2.merge_batches(temp_batch,next(train_iter_[0]))\n",
    "            temp_batch = load_dataset2.merge_batches(temp_batch,next(train_iter_[0]))\n",
    "            if(easy_mode):\n",
    "                temp_batch = load_dataset2.merge_batches(temp_batch,next(train_iter_[0]))\n",
    "            else:\n",
    "                temp_batch = load_dataset2.merge_batches(temp_batch,next(train_iter_[1]))\n",
    "            \n",
    "            train_batch = load_dataset2.shuffle_data_batch(temp_batch)\n",
    "\n",
    "            _,_,train_Tloss,train_L2loss = sess.run([apply_gradient_op, extra_update_ops, pred_Tloss, pred_L2loss],\n",
    "                                                  feed_dict= {                                                                  \n",
    "                                                      input_img: train_batch['imgs_ori'],\n",
    "                                                      input_fp: train_batch['fp'][:,:,:,0:conf.ef_dim],\n",
    "                                                      input_ang: train_batch['tar_agl']-train_batch['sur_agl'],\n",
    "                                                      img_: train_batch['imgs__ori'],\n",
    "                                                      learning_rate: cur_lr,\n",
    "                                                      phase_train: True,\n",
    "                                                      input_eye_msk: train_batch['msk_eye']\n",
    "                                                  })\n",
    "            batch_duration = time.time() - batch_start_time\n",
    "\n",
    "            if (steps % step_per_epoch == 0):                   \n",
    "                print('-- Step %d, [T] Tloss=%.1f, L2loss=%.1f (%.1fs)' % (steps, np.mean(train_Tloss), np.mean(train_L2loss),  batch_duration))\n",
    "                fout.write(str('%d,%.4f,NA,%.4f,NA,NA\\n' % (steps, np.mean(train_Tloss),np.mean(train_L2loss))))\n",
    "                fout.flush()\n",
    "\n",
    "        # Stop if early stop\n",
    "        if (stop_counter > conf.early_stop):\n",
    "            break\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process (easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------0/500------\n",
      "-- Step 0, [V*] eT=8679.3, eL2=2103.5; hT=8902.6, hL2=2115.1\n",
      "-- Step 0, [T] Tloss=6451.1, L2loss=1168.1 (20.5s)\n",
      "-- Step 3, [V*] eT=5349.9, eL2=1696.5; hT=5746.8, hL2=1901.6\n",
      "------1/500------\n",
      "-- Step 6, [V*] eT=3941.1, eL2=1349.5; hT=4328.7, hL2=1542.3\n",
      "-- Step 6, [T] Tloss=3083.8, L2loss=1131.5 (13.8s)\n",
      "-- Step 9, [V*] eT=3099.0, eL2=1125.8; hT=3384.0, hL2=1263.5\n",
      "------2/500------\n",
      "-- Step 12, [V*] eT=2772.8, eL2=1061.0; hT=3024.2, hL2=1186.8\n",
      "-- Step 12, [T] Tloss=2666.7, L2loss=1088.4 (14.5s)\n",
      "-- Step 15, [V*] eT=2661.0, eL2=1051.8; hT=2890.0, hL2=1170.0\n",
      "------3/500------\n",
      "-- Step 18, [V*] eT=2438.7, eL2=951.3; hT=2697.9, hL2=1105.1\n",
      "-- Step 18, [T] Tloss=2462.0, L2loss=1014.9 (14.0s)\n",
      "-- Step 21, [V*] eT=2413.0, eL2=913.6; hT=2635.7, hL2=1054.8\n",
      "------4/500------\n",
      "-- Step 24, [V*] eT=2291.4, eL2=885.5; hT=2530.7, hL2=1038.1\n",
      "-- Step 24, [T] Tloss=2367.5, L2loss=992.4 (14.0s)\n",
      "-- Step 27, [V*] eT=2276.7, eL2=918.6; hT=2484.0, hL2=1048.7\n",
      "------5/500------\n",
      "-- Step 30, [V*] eT=2183.8, eL2=872.8; hT=2374.9, hL2=995.8\n",
      "-- Step 30, [T] Tloss=2236.0, L2loss=945.9 (14.1s)\n",
      "-- Step 33, [V*] eT=2160.5, eL2=885.2; hT=2329.8, hL2=996.5\n",
      "------6/500------\n",
      "-- Step 36, [V] eT=2301.5, eL2=998.9; hT=2484.4, hL2=1108.0\n",
      "-- Step 36, [T] Tloss=2176.5, L2loss=963.5 (9.7s)\n",
      "-- Step 39, [V] eT=2197.3, eL2=955.9; hT=2355.1, hL2=1057.0\n",
      "------7/500------\n",
      "-- Step 42, [V*] eT=2015.0, eL2=868.0; hT=2165.5, hL2=971.7\n",
      "-- Step 42, [T] Tloss=2071.5, L2loss=935.2 (14.4s)\n",
      "-- Step 45, [V*] eT=2013.6, eL2=877.8; hT=2152.6, hL2=979.7\n",
      "------8/500------\n",
      "-- Step 48, [V*] eT=1801.5, eL2=774.0; hT=1946.2, hL2=885.1\n",
      "-- Step 48, [T] Tloss=2009.4, L2loss=933.9 (14.3s)\n",
      "-- Step 51, [V*] eT=1794.3, eL2=771.0; hT=1932.3, hL2=882.1\n",
      "------9/500------\n",
      "-- Step 54, [V*] eT=1690.0, eL2=738.6; hT=1858.9, hL2=868.7\n",
      "-- Step 54, [T] Tloss=1944.0, L2loss=913.3 (14.5s)\n",
      "-- Step 57, [V] eT=1913.8, eL2=876.1; hT=2045.9, hL2=979.5\n",
      "------10/500------\n",
      "-- Step 60, [V] eT=1768.2, eL2=787.4; hT=1903.8, hL2=903.0\n",
      "-- Step 60, [T] Tloss=1899.4, L2loss=881.9 (9.6s)\n",
      "-- Step 63, [V] eT=1697.8, eL2=747.3; hT=1829.0, hL2=861.1\n",
      "------11/500------\n",
      "-- Step 66, [V*] eT=1687.3, eL2=750.8; hT=1830.1, hL2=878.6\n",
      "-- Step 66, [T] Tloss=1841.7, L2loss=867.0 (14.6s)\n",
      "-- Step 69, [V*] eT=1650.0, eL2=746.9; hT=1787.8, hL2=867.6\n",
      "------12/500------\n",
      "-- Step 72, [V] eT=1746.0, eL2=822.7; hT=1897.5, hL2=947.9\n",
      "-- Step 72, [T] Tloss=1796.1, L2loss=865.5 (9.6s)\n",
      "-- Step 75, [V] eT=1664.3, eL2=759.7; hT=1807.5, hL2=891.5\n",
      "------13/500------\n",
      "-- Step 78, [V] eT=1711.6, eL2=811.3; hT=1856.0, hL2=934.3\n",
      "-- Step 78, [T] Tloss=1765.2, L2loss=869.1 (9.6s)\n",
      "-- Step 81, [V*] eT=1584.9, eL2=742.7; hT=1701.9, hL2=857.5\n",
      "------14/500------\n",
      "-- Step 84, [V*] eT=1505.6, eL2=687.5; hT=1638.4, hL2=816.9\n",
      "-- Step 84, [T] Tloss=1726.1, L2loss=834.1 (14.1s)\n",
      "-- Step 87, [V] eT=1779.0, eL2=908.9; hT=1881.1, hL2=999.4\n",
      "------15/500------\n",
      "-- Step 90, [V] eT=1611.5, eL2=766.6; hT=1743.3, hL2=883.2\n",
      "-- Step 90, [T] Tloss=1679.9, L2loss=822.4 (9.7s)\n",
      "-- Step 93, [V] eT=1579.5, eL2=773.6; hT=1721.6, hL2=904.4\n",
      "------16/500------\n",
      "-- Step 96, [V] eT=1618.1, eL2=822.6; hT=1766.7, hL2=953.7\n",
      "-- Step 96, [T] Tloss=1632.7, L2loss=842.3 (9.8s)\n",
      "-- Step 99, [V*] eT=1476.0, eL2=729.8; hT=1635.2, hL2=881.2\n",
      "------17/500------\n",
      "-- Step 102, [V] eT=1583.9, eL2=842.5; hT=1722.9, hL2=970.5\n",
      "-- Step 102, [T] Tloss=1583.0, L2loss=844.8 (9.6s)\n",
      "-- Step 105, [V] eT=1751.4, eL2=912.1; hT=1911.1, hL2=1051.4\n",
      "------18/500------\n",
      "-- Step 108, [V*] eT=1426.6, eL2=717.7; hT=1579.4, hL2=868.2\n",
      "-- Step 108, [T] Tloss=1531.2, L2loss=789.2 (14.3s)\n",
      "-- Step 111, [V] eT=1561.7, eL2=867.0; hT=1686.1, hL2=978.8\n",
      "------19/500------\n",
      "-- Step 114, [V] eT=1448.7, eL2=762.8; hT=1601.0, hL2=899.8\n",
      "-- Step 114, [T] Tloss=1470.6, L2loss=781.3 (9.8s)\n",
      "-- Step 117, [V*] eT=1422.3, eL2=742.1; hT=1589.4, hL2=900.4\n",
      "------20/500------\n",
      "-- Step 120, [V] eT=1441.1, eL2=755.1; hT=1598.6, hL2=898.2\n",
      "-- Step 120, [T] Tloss=1448.6, L2loss=758.6 (9.7s)\n",
      "-- Step 123, [V*] eT=1327.1, eL2=694.3; hT=1450.3, hL2=824.2\n",
      "------21/500------\n",
      "-- Step 126, [V*] eT=1327.1, eL2=707.5; hT=1456.7, hL2=841.6\n",
      "-- Step 126, [T] Tloss=1373.4, L2loss=739.1 (14.3s)\n",
      "-- Step 129, [V] eT=1432.2, eL2=777.4; hT=1591.3, hL2=919.6\n",
      "------22/500------\n",
      "-- Step 132, [V] eT=1384.6, eL2=760.3; hT=1533.7, hL2=895.0\n",
      "-- Step 132, [T] Tloss=1356.1, L2loss=733.1 (9.6s)\n",
      "-- Step 135, [V*] eT=1268.9, eL2=686.8; hT=1398.2, hL2=822.8\n",
      "------23/500------\n",
      "-- Step 138, [V] eT=2722.8, eL2=1546.4; hT=2829.2, hL2=1604.4\n",
      "-- Step 138, [T] Tloss=1433.7, L2loss=880.5 (9.8s)\n",
      "-- Step 141, [V*] eT=1214.6, eL2=717.4; hT=1281.2, hL2=782.7\n",
      "------24/500------\n",
      "-- Step 144, [V*] eT=1158.5, eL2=693.1; hT=1246.0, hL2=772.3\n",
      "-- Step 144, [T] Tloss=1217.3, L2loss=736.1 (14.6s)\n",
      "-- Step 147, [V*] eT=1137.6, eL2=686.8; hT=1257.3, hL2=797.1\n",
      "------25/500------\n",
      "-- Step 150, [V*] eT=1104.1, eL2=665.3; hT=1241.9, hL2=793.2\n",
      "-- Step 150, [T] Tloss=1189.9, L2loss=720.2 (14.3s)\n",
      "-- Step 153, [V] eT=1116.5, eL2=691.0; hT=1246.3, hL2=811.3\n",
      "------26/500------\n",
      "-- Step 156, [V*] eT=1024.3, eL2=610.5; hT=1153.7, hL2=733.1\n",
      "-- Step 156, [T] Tloss=1131.1, L2loss=682.1 (14.5s)\n",
      "-- Step 159, [V] eT=1111.8, eL2=698.4; hT=1232.2, hL2=806.5\n",
      "------27/500------\n",
      "-- Step 162, [V] eT=1073.1, eL2=671.2; hT=1207.2, hL2=796.6\n",
      "-- Step 162, [T] Tloss=1087.0, L2loss=669.8 (9.6s)\n",
      "-- Step 165, [V*] eT=1020.7, eL2=627.0; hT=1166.9, hL2=760.0\n",
      "------28/500------\n",
      "-- Step 168, [V] eT=1065.5, eL2=674.0; hT=1221.1, hL2=816.8\n",
      "-- Step 168, [T] Tloss=1060.5, L2loss=664.8 (9.7s)\n",
      "-- Step 171, [V*] eT=962.6, eL2=578.5; hT=1108.3, hL2=717.5\n",
      "------29/500------\n",
      "-- Step 174, [V] eT=1073.6, eL2=690.0; hT=1223.9, hL2=826.5\n",
      "-- Step 174, [T] Tloss=1047.4, L2loss=661.3 (9.7s)\n",
      "-- Step 177, [V] eT=1040.4, eL2=676.0; hT=1195.1, hL2=817.3\n",
      "------30/500------\n",
      "-- Step 180, [V*] eT=952.5, eL2=597.4; hT=1108.0, hL2=741.1\n",
      "-- Step 180, [T] Tloss=981.9, L2loss=611.0 (14.3s)\n",
      "-- Step 183, [V*] eT=887.4, eL2=543.2; hT=1035.6, hL2=684.0\n",
      "------31/500------\n",
      "-- Step 186, [V] eT=1020.5, eL2=679.5; hT=1160.7, hL2=805.3\n",
      "-- Step 186, [T] Tloss=958.1, L2loss=609.8 (9.5s)\n",
      "-- Step 189, [V] eT=928.2, eL2=588.1; hT=1089.5, hL2=741.4\n",
      "------32/500------\n",
      "-- Step 192, [V*] eT=861.8, eL2=519.6; hT=1014.9, hL2=664.4\n",
      "-- Step 192, [T] Tloss=955.3, L2loss=587.7 (14.5s)\n",
      "-- Step 195, [V] eT=877.8, eL2=562.8; hT=1045.5, hL2=716.5\n",
      "------33/500------\n",
      "-- Step 198, [V] eT=1014.7, eL2=687.7; hT=1180.7, hL2=834.8\n",
      "-- Step 198, [T] Tloss=903.8, L2loss=584.1 (9.5s)\n",
      "-- Step 201, [V] eT=906.0, eL2=595.4; hT=1080.0, hL2=751.7\n",
      "------34/500------\n",
      "-- Step 204, [V*] eT=852.1, eL2=531.7; hT=1050.7, hL2=715.3\n",
      "-- Step 204, [T] Tloss=880.3, L2loss=546.1 (14.2s)\n",
      "-- Step 207, [V*] eT=819.0, eL2=512.5; hT=1011.5, hL2=678.4\n",
      "------35/500------\n",
      "-- Step 210, [V] eT=990.6, eL2=674.2; hT=1183.1, hL2=830.5\n",
      "-- Step 210, [T] Tloss=860.7, L2loss=556.9 (9.7s)\n",
      "-- Step 213, [V] eT=824.9, eL2=526.6; hT=1038.6, hL2=718.7\n",
      "------36/500------\n",
      "-- Step 216, [V] eT=891.6, eL2=605.7; hT=1073.7, hL2=764.4\n",
      "-- Step 216, [T] Tloss=820.2, L2loss=528.6 (9.8s)\n",
      "-- Step 219, [V*] eT=789.5, eL2=503.0; hT=1006.6, hL2=693.2\n",
      "------37/500------\n",
      "-- Step 222, [V] eT=926.3, eL2=640.2; hT=1130.8, hL2=818.4\n",
      "-- Step 222, [T] Tloss=799.8, L2loss=518.5 (9.7s)\n",
      "-- Step 225, [V] eT=859.8, eL2=572.6; hT=1051.2, hL2=741.2\n",
      "------38/500------\n",
      "-- Step 228, [V*] eT=775.4, eL2=496.6; hT=968.9, hL2=668.1\n",
      "-- Step 228, [T] Tloss=780.8, L2loss=479.7 (14.3s)\n",
      "-- Step 231, [V] eT=828.7, eL2=541.9; hT=1015.1, hL2=698.6\n",
      "------39/500------\n",
      "-- Step 234, [V*] eT=774.7, eL2=496.7; hT=958.7, hL2=663.4\n",
      "-- Step 234, [T] Tloss=754.5, L2loss=469.1 (14.5s)\n",
      "-- Step 237, [V] eT=906.3, eL2=626.4; hT=1132.4, hL2=799.9\n",
      "------40/500------\n",
      "-- Step 240, [V*] eT=751.3, eL2=499.8; hT=958.1, hL2=673.1\n",
      "-- Step 240, [T] Tloss=710.2, L2loss=452.1 (14.4s)\n",
      "-- Step 243, [V] eT=879.5, eL2=618.9; hT=1038.5, hL2=763.0\n",
      "------41/500------\n",
      "-- Step 246, [V*] eT=704.0, eL2=456.7; hT=898.3, hL2=635.0\n",
      "-- Step 246, [T] Tloss=697.8, L2loss=437.3 (14.6s)\n",
      "-- Step 249, [V] eT=777.0, eL2=526.7; hT=1003.8, hL2=713.5\n",
      "------42/500------\n",
      "-- Step 252, [V] eT=866.4, eL2=620.9; hT=1087.0, hL2=786.3\n",
      "-- Step 252, [T] Tloss=676.9, L2loss=447.5 (9.7s)\n",
      "-- Step 255, [V] eT=716.0, eL2=480.9; hT=926.4, hL2=661.8\n",
      "------43/500------\n",
      "-- Step 258, [V] eT=723.6, eL2=496.2; hT=912.1, hL2=663.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Step 258, [T] Tloss=654.0, L2loss=425.4 (9.6s)\n",
      "-- Step 261, [V] eT=719.1, eL2=493.7; hT=884.3, hL2=641.8\n",
      "Decreasing lr to 0.000900\n",
      "------44/500------\n",
      "-- Step 264, [V] eT=723.6, eL2=504.9; hT=914.2, hL2=666.4\n",
      "-- Step 264, [T] Tloss=632.5, L2loss=410.0 (9.6s)\n",
      "-- Step 267, [V*] eT=681.8, eL2=466.3; hT=876.9, hL2=641.5\n",
      "------45/500------\n",
      "-- Step 270, [V] eT=689.4, eL2=473.8; hT=876.9, hL2=638.0\n",
      "-- Step 270, [T] Tloss=624.8, L2loss=399.3 (9.6s)\n",
      "-- Step 273, [V*] eT=659.5, eL2=448.7; hT=844.0, hL2=617.4\n",
      "------46/500------\n",
      "-- Step 276, [V] eT=1084.9, eL2=810.3; hT=1259.3, hL2=903.7\n",
      "-- Step 276, [T] Tloss=630.5, L2loss=436.6 (9.6s)\n",
      "-- Step 279, [V*] eT=649.5, eL2=444.8; hT=837.0, hL2=610.9\n",
      "------47/500------\n",
      "-- Step 282, [V*] eT=639.2, eL2=433.6; hT=814.1, hL2=592.7\n",
      "-- Step 282, [T] Tloss=604.4, L2loss=384.9 (14.3s)\n",
      "-- Step 285, [V] eT=656.5, eL2=457.5; hT=866.1, hL2=636.6\n",
      "------48/500------\n",
      "-- Step 288, [V] eT=644.4, eL2=440.0; hT=830.9, hL2=599.0\n",
      "-- Step 288, [T] Tloss=580.3, L2loss=369.4 (9.9s)\n",
      "-- Step 291, [V] eT=656.8, eL2=453.4; hT=853.1, hL2=624.8\n",
      "------49/500------\n",
      "-- Step 294, [V*] eT=625.4, eL2=432.7; hT=801.8, hL2=590.6\n",
      "-- Step 294, [T] Tloss=562.9, L2loss=365.4 (14.3s)\n",
      "-- Step 297, [V] eT=643.7, eL2=450.6; hT=821.4, hL2=610.9\n",
      "------50/500------\n",
      "-- Step 300, [V] eT=646.6, eL2=448.6; hT=821.8, hL2=608.0\n",
      "-- Step 300, [T] Tloss=557.1, L2loss=359.1 (9.5s)\n",
      "-- Step 303, [V] eT=648.5, eL2=456.5; hT=838.3, hL2=621.8\n",
      "------51/500------\n",
      "-- Step 306, [V] eT=637.9, eL2=442.1; hT=814.4, hL2=599.4\n",
      "-- Step 306, [T] Tloss=556.0, L2loss=358.7 (9.7s)\n",
      "-- Step 309, [V] eT=631.4, eL2=437.7; hT=805.2, hL2=595.7\n",
      "Decreasing lr to 0.000810\n",
      "------52/500------\n",
      "-- Step 312, [V*] eT=604.3, eL2=421.7; hT=818.1, hL2=604.3\n",
      "-- Step 312, [T] Tloss=522.9, L2loss=339.6 (14.4s)\n",
      "-- Step 315, [V*] eT=584.8, eL2=406.3; hT=763.8, hL2=570.0\n",
      "------53/500------\n",
      "-- Step 318, [V*] eT=584.5, eL2=406.4; hT=801.0, hL2=595.8\n",
      "-- Step 318, [T] Tloss=516.3, L2loss=334.0 (14.5s)\n",
      "-- Step 321, [V] eT=618.4, eL2=440.8; hT=817.1, hL2=614.2\n",
      "------54/500------\n",
      "-- Step 324, [V] eT=603.5, eL2=426.6; hT=794.2, hL2=597.1\n",
      "-- Step 324, [T] Tloss=513.2, L2loss=340.2 (9.7s)\n",
      "-- Step 327, [V*] eT=574.3, eL2=397.3; hT=760.8, hL2=564.5\n",
      "------55/500------\n",
      "-- Step 330, [V] eT=614.1, eL2=439.8; hT=810.9, hL2=611.3\n",
      "-- Step 330, [T] Tloss=511.4, L2loss=342.6 (9.8s)\n",
      "-- Step 333, [V] eT=587.6, eL2=416.4; hT=790.5, hL2=596.4\n",
      "------56/500------\n",
      "-- Step 336, [V] eT=584.0, eL2=414.6; hT=798.8, hL2=603.6\n",
      "-- Step 336, [T] Tloss=493.2, L2loss=328.0 (9.8s)\n",
      "-- Step 339, [V*] eT=558.7, eL2=391.5; hT=748.0, hL2=561.9\n",
      "------57/500------\n",
      "-- Step 342, [V] eT=573.6, eL2=405.9; hT=766.8, hL2=580.2\n",
      "-- Step 342, [T] Tloss=489.8, L2loss=327.1 (9.9s)\n",
      "-- Step 345, [V] eT=569.5, eL2=399.5; hT=759.8, hL2=568.1\n",
      "------58/500------\n",
      "-- Step 348, [V] eT=576.0, eL2=407.2; hT=775.9, hL2=583.7\n",
      "-- Step 348, [T] Tloss=481.8, L2loss=318.2 (9.8s)\n",
      "-- Step 351, [V*] eT=542.6, eL2=382.1; hT=746.1, hL2=562.7\n",
      "------59/500------\n",
      "-- Step 354, [V] eT=589.1, eL2=425.7; hT=790.4, hL2=600.2\n",
      "-- Step 354, [T] Tloss=475.7, L2loss=317.8 (9.7s)\n",
      "-- Step 357, [V] eT=574.6, eL2=411.5; hT=759.6, hL2=576.2\n",
      "------60/500------\n",
      "-- Step 360, [V*] eT=537.3, eL2=374.6; hT=735.2, hL2=551.1\n",
      "-- Step 360, [T] Tloss=478.7, L2loss=312.0 (14.3s)\n",
      "-- Step 363, [V*] eT=528.7, eL2=373.7; hT=716.7, hL2=544.3\n",
      "------61/500------\n",
      "-- Step 366, [V] eT=563.6, eL2=405.8; hT=763.1, hL2=579.8\n",
      "-- Step 366, [T] Tloss=464.7, L2loss=311.9 (9.5s)\n",
      "-- Step 369, [V] eT=543.0, eL2=387.7; hT=745.0, hL2=567.3\n",
      "------62/500------\n",
      "-- Step 372, [V] eT=583.7, eL2=419.6; hT=797.9, hL2=595.8\n",
      "-- Step 372, [T] Tloss=456.2, L2loss=303.8 (9.6s)\n",
      "-- Step 375, [V] eT=578.6, eL2=423.3; hT=813.5, hL2=610.7\n",
      "------63/500------\n",
      "-- Step 378, [V] eT=546.6, eL2=395.3; hT=759.2, hL2=577.1\n",
      "Decreasing lr to 0.000729\n",
      "-- Step 378, [T] Tloss=441.3, L2loss=295.6 (9.6s)\n",
      "-- Step 381, [V] eT=555.1, eL2=399.2; hT=786.1, hL2=591.1\n",
      "------64/500------\n",
      "-- Step 384, [V*] eT=525.7, eL2=380.6; hT=731.6, hL2=560.3\n",
      "-- Step 384, [T] Tloss=432.7, L2loss=292.4 (14.4s)\n",
      "-- Step 387, [V] eT=526.4, eL2=374.2; hT=728.5, hL2=553.5\n",
      "------65/500------\n",
      "-- Step 390, [V] eT=536.4, eL2=388.1; hT=744.6, hL2=566.7\n",
      "-- Step 390, [T] Tloss=428.5, L2loss=288.7 (9.8s)\n",
      "-- Step 393, [V*] eT=512.1, eL2=363.7; hT=713.0, hL2=541.4\n",
      "------66/500------\n",
      "-- Step 396, [V*] eT=511.9, eL2=367.8; hT=711.4, hL2=544.8\n",
      "-- Step 396, [T] Tloss=431.3, L2loss=288.9 (14.2s)\n",
      "-- Step 399, [V] eT=538.5, eL2=392.3; hT=747.4, hL2=574.2\n",
      "------67/500------\n",
      "-- Step 402, [V] eT=548.7, eL2=402.2; hT=755.5, hL2=580.2\n",
      "-- Step 402, [T] Tloss=424.0, L2loss=289.3 (9.6s)\n",
      "-- Step 405, [V] eT=512.1, eL2=370.5; hT=707.2, hL2=544.2\n",
      "------68/500------\n",
      "-- Step 408, [V] eT=522.8, eL2=376.4; hT=721.3, hL2=555.8\n",
      "-- Step 408, [T] Tloss=422.7, L2loss=285.5 (9.7s)\n",
      "-- Step 411, [V*] eT=495.7, eL2=356.1; hT=683.8, hL2=524.4\n",
      "------69/500------\n",
      "-- Step 414, [V*] eT=486.9, eL2=348.8; hT=675.9, hL2=519.3\n",
      "-- Step 414, [T] Tloss=418.5, L2loss=279.6 (14.3s)\n",
      "-- Step 417, [V] eT=508.2, eL2=368.7; hT=696.3, hL2=538.7\n",
      "------70/500------\n",
      "-- Step 420, [V*] eT=480.2, eL2=343.9; hT=680.5, hL2=525.6\n",
      "-- Step 420, [T] Tloss=408.9, L2loss=272.9 (14.4s)\n",
      "-- Step 423, [V] eT=519.3, eL2=380.9; hT=736.8, hL2=569.9\n",
      "------71/500------\n",
      "-- Step 426, [V] eT=503.9, eL2=367.9; hT=711.8, hL2=551.9\n",
      "-- Step 426, [T] Tloss=402.9, L2loss=272.4 (9.6s)\n",
      "-- Step 429, [V] eT=481.3, eL2=347.1; hT=681.5, hL2=528.8\n",
      "------72/500------\n",
      "-- Step 432, [V] eT=482.9, eL2=350.5; hT=698.9, hL2=543.6\n",
      "-- Step 432, [T] Tloss=403.3, L2loss=274.8 (9.7s)\n",
      "-- Step 435, [V] eT=486.5, eL2=352.1; hT=706.6, hL2=544.8\n",
      "Decreasing lr to 0.000656\n",
      "------73/500------\n",
      "-- Step 438, [V] eT=501.7, eL2=368.6; hT=709.2, hL2=553.1\n",
      "-- Step 438, [T] Tloss=391.4, L2loss=265.3 (9.8s)\n",
      "-- Step 441, [V] eT=488.4, eL2=356.4; hT=689.6, hL2=537.4\n",
      "------74/500------\n",
      "-- Step 444, [V] eT=496.1, eL2=364.6; hT=712.2, hL2=556.0\n",
      "-- Step 444, [T] Tloss=388.0, L2loss=264.6 (9.8s)\n",
      "-- Step 447, [V*] eT=473.9, eL2=346.7; hT=680.4, hL2=531.7\n",
      "------75/500------\n",
      "-- Step 450, [V] eT=506.6, eL2=374.7; hT=739.5, hL2=574.4\n",
      "-- Step 450, [T] Tloss=387.1, L2loss=266.3 (9.6s)\n",
      "-- Step 453, [V] eT=516.7, eL2=382.6; hT=765.5, hL2=587.4\n",
      "------76/500------\n",
      "-- Step 456, [V] eT=483.7, eL2=357.4; hT=704.3, hL2=551.0\n",
      "-- Step 456, [T] Tloss=384.1, L2loss=266.7 (9.7s)\n",
      "-- Step 459, [V] eT=479.9, eL2=348.9; hT=694.0, hL2=539.5\n",
      "------77/500------\n",
      "-- Step 462, [V*] eT=462.9, eL2=339.2; hT=679.9, hL2=533.0\n",
      "-- Step 462, [T] Tloss=374.6, L2loss=256.6 (14.4s)\n",
      "-- Step 465, [V] eT=483.3, eL2=353.3; hT=682.1, hL2=530.9\n",
      "------78/500------\n",
      "-- Step 468, [V*] eT=458.1, eL2=335.7; hT=664.0, hL2=519.2\n",
      "-- Step 468, [T] Tloss=375.9, L2loss=258.2 (14.4s)\n",
      "-- Step 471, [V] eT=478.9, eL2=353.6; hT=693.9, hL2=541.7\n",
      "------79/500------\n",
      "-- Step 474, [V] eT=522.8, eL2=397.6; hT=772.5, hL2=609.5\n",
      "-- Step 474, [T] Tloss=379.3, L2loss=269.4 (9.6s)\n",
      "-- Step 477, [V] eT=482.3, eL2=357.3; hT=692.0, hL2=541.8\n",
      "------80/500------\n",
      "-- Step 480, [V] eT=470.3, eL2=349.8; hT=680.3, hL2=535.8\n",
      "-- Step 480, [T] Tloss=373.9, L2loss=258.3 (9.6s)\n",
      "-- Step 483, [V] eT=479.5, eL2=355.7; hT=702.6, hL2=552.1\n",
      "Decreasing lr to 0.000590\n",
      "------81/500------\n",
      "-- Step 486, [V*] eT=445.1, eL2=327.8; hT=652.5, hL2=514.1\n",
      "-- Step 486, [T] Tloss=363.2, L2loss=248.6 (14.6s)\n",
      "-- Step 489, [V] eT=450.8, eL2=332.2; hT=669.6, hL2=526.8\n",
      "------82/500------\n",
      "-- Step 492, [V] eT=458.1, eL2=341.2; hT=673.9, hL2=532.6\n",
      "-- Step 492, [T] Tloss=361.4, L2loss=249.8 (9.8s)\n",
      "-- Step 495, [V] eT=456.8, eL2=337.5; hT=664.7, hL2=522.2\n",
      "------83/500------\n",
      "-- Step 498, [V] eT=455.2, eL2=338.7; hT=667.3, hL2=526.0\n",
      "-- Step 498, [T] Tloss=355.4, L2loss=243.7 (9.9s)\n",
      "-- Step 501, [V] eT=454.5, eL2=336.5; hT=659.6, hL2=517.4\n",
      "Decreasing lr to 0.000531\n",
      "------84/500------\n",
      "-- Step 504, [V*] eT=441.1, eL2=326.6; hT=647.0, hL2=510.0\n",
      "-- Step 504, [T] Tloss=350.4, L2loss=244.3 (14.6s)\n",
      "-- Step 507, [V] eT=448.4, eL2=334.7; hT=666.9, hL2=524.7\n",
      "------85/500------\n",
      "-- Step 510, [V*] eT=439.5, eL2=326.4; hT=651.0, hL2=512.9\n",
      "-- Step 510, [T] Tloss=349.4, L2loss=242.8 (14.5s)\n",
      "-- Step 513, [V*] eT=439.2, eL2=328.5; hT=653.1, hL2=516.8\n",
      "------86/500------\n",
      "-- Step 516, [V*] eT=438.0, eL2=324.8; hT=645.9, hL2=506.7\n",
      "-- Step 516, [T] Tloss=349.5, L2loss=243.0 (14.2s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Step 519, [V] eT=439.3, eL2=332.6; hT=652.7, hL2=520.2\n",
      "------87/500------\n",
      "-- Step 522, [V*] eT=437.9, eL2=329.6; hT=652.9, hL2=519.1\n",
      "-- Step 522, [T] Tloss=347.1, L2loss=245.8 (14.5s)\n",
      "-- Step 525, [V*] eT=427.3, eL2=325.8; hT=635.2, hL2=508.3\n",
      "------88/500------\n",
      "-- Step 528, [V] eT=436.0, eL2=331.1; hT=649.8, hL2=518.8\n",
      "-- Step 528, [T] Tloss=343.9, L2loss=244.3 (9.6s)\n",
      "-- Step 531, [V*] eT=404.9, eL2=308.2; hT=617.3, hL2=496.6\n",
      "------89/500------\n",
      "-- Step 534, [V*] eT=399.0, eL2=298.5; hT=603.6, hL2=481.0\n",
      "-- Step 534, [T] Tloss=334.8, L2loss=235.1 (14.2s)\n",
      "-- Step 537, [V] eT=407.7, eL2=311.3; hT=610.9, hL2=490.8\n",
      "------90/500------\n",
      "-- Step 540, [V] eT=404.6, eL2=303.9; hT=614.7, hL2=490.3\n",
      "-- Step 540, [T] Tloss=331.6, L2loss=234.2 (9.7s)\n",
      "-- Step 543, [V] eT=409.3, eL2=315.2; hT=615.7, hL2=498.3\n",
      "------91/500------\n",
      "-- Step 546, [V] eT=399.1, eL2=301.0; hT=606.0, hL2=484.8\n",
      "-- Step 546, [T] Tloss=329.6, L2loss=236.8 (9.7s)\n",
      "-- Step 549, [V*] eT=390.4, eL2=299.9; hT=618.1, hL2=500.8\n",
      "------92/500------\n",
      "-- Step 552, [V] eT=398.4, eL2=305.3; hT=608.8, hL2=491.8\n",
      "-- Step 552, [T] Tloss=320.6, L2loss=230.6 (9.6s)\n",
      "-- Step 555, [V] eT=392.2, eL2=302.0; hT=609.9, hL2=494.4\n",
      "------93/500------\n",
      "-- Step 558, [V*] eT=385.6, eL2=294.1; hT=605.4, hL2=489.7\n",
      "-- Step 558, [T] Tloss=319.7, L2loss=231.0 (14.5s)\n",
      "-- Step 561, [V*] eT=381.4, eL2=293.5; hT=589.5, hL2=478.7\n",
      "------94/500------\n",
      "-- Step 564, [V*] eT=382.5, eL2=292.2; hT=584.2, hL2=472.0\n",
      "-- Step 564, [T] Tloss=320.7, L2loss=230.5 (14.2s)\n",
      "-- Step 567, [V*] eT=376.2, eL2=290.1; hT=579.0, hL2=470.6\n",
      "------95/500------\n",
      "-- Step 570, [V] eT=392.9, eL2=300.1; hT=609.8, hL2=489.9\n",
      "-- Step 570, [T] Tloss=320.9, L2loss=231.5 (9.7s)\n",
      "-- Step 573, [V*] eT=369.8, eL2=285.5; hT=590.5, hL2=479.3\n",
      "------96/500------\n",
      "-- Step 576, [V] eT=401.3, eL2=313.4; hT=616.4, hL2=501.0\n",
      "-- Step 576, [T] Tloss=312.4, L2loss=231.6 (9.6s)\n",
      "-- Step 579, [V] eT=373.5, eL2=288.5; hT=583.8, hL2=473.8\n",
      "------97/500------\n",
      "-- Step 582, [V] eT=384.9, eL2=299.4; hT=604.9, hL2=491.8\n",
      "-- Step 582, [T] Tloss=307.8, L2loss=225.2 (9.8s)\n",
      "-- Step 585, [V] eT=391.1, eL2=304.2; hT=593.6, hL2=481.6\n",
      "------98/500------\n",
      "-- Step 588, [V] eT=373.1, eL2=291.1; hT=574.2, hL2=468.7\n",
      "Decreasing lr to 0.000478\n",
      "-- Step 588, [T] Tloss=305.2, L2loss=223.4 (9.9s)\n",
      "-- Step 591, [V*] eT=359.8, eL2=276.3; hT=575.1, hL2=468.0\n",
      "------99/500------\n",
      "-- Step 594, [V] eT=370.7, eL2=289.8; hT=580.0, hL2=475.2\n",
      "-- Step 594, [T] Tloss=300.3, L2loss=221.0 (9.7s)\n",
      "-- Step 597, [V] eT=373.8, eL2=289.7; hT=589.2, hL2=478.9\n",
      "------100/500------\n",
      "-- Step 600, [V] eT=377.6, eL2=295.6; hT=599.9, hL2=490.1\n",
      "-- Step 600, [T] Tloss=298.9, L2loss=220.1 (9.9s)\n",
      "-- Step 603, [V] eT=368.1, eL2=286.5; hT=579.5, hL2=471.1\n",
      "------101/500------\n",
      "-- Step 606, [V] eT=366.3, eL2=287.6; hT=573.4, hL2=472.0\n",
      "Decreasing lr to 0.000430\n",
      "-- Step 606, [T] Tloss=291.0, L2loss=213.8 (9.9s)\n",
      "-- Step 609, [V] eT=365.6, eL2=285.3; hT=589.7, hL2=479.3\n",
      "------102/500------\n",
      "-- Step 612, [V*] eT=358.4, eL2=279.4; hT=567.0, hL2=463.3\n",
      "-- Step 612, [T] Tloss=294.5, L2loss=213.7 (14.6s)\n",
      "-- Step 615, [V*] eT=357.1, eL2=279.4; hT=569.7, hL2=466.2\n",
      "------103/500------\n",
      "-- Step 618, [V] eT=365.6, eL2=285.7; hT=575.9, hL2=468.4\n",
      "-- Step 618, [T] Tloss=292.2, L2loss=215.8 (9.7s)\n",
      "-- Step 621, [V] eT=364.5, eL2=286.8; hT=586.6, hL2=479.7\n",
      "------104/500------\n",
      "-- Step 624, [V] eT=360.9, eL2=280.6; hT=564.1, hL2=459.6\n",
      "-- Step 624, [T] Tloss=295.4, L2loss=216.7 (9.6s)\n",
      "-- Step 627, [V] eT=357.7, eL2=281.0; hT=576.3, hL2=471.1\n",
      "------105/500------\n",
      "-- Step 630, [V*] eT=355.3, eL2=279.3; hT=572.0, hL2=467.8\n",
      "-- Step 630, [T] Tloss=287.8, L2loss=214.4 (14.3s)\n",
      "-- Step 633, [V] eT=359.2, eL2=279.9; hT=576.1, hL2=469.5\n",
      "------106/500------\n",
      "-- Step 636, [V] eT=360.8, eL2=283.9; hT=573.3, hL2=469.4\n",
      "-- Step 636, [T] Tloss=285.6, L2loss=212.2 (9.8s)\n",
      "-- Step 639, [V] eT=366.9, eL2=287.5; hT=585.5, hL2=477.5\n",
      "------107/500------\n",
      "-- Step 642, [V*] eT=347.2, eL2=273.0; hT=562.5, hL2=462.1\n",
      "-- Step 642, [T] Tloss=285.8, L2loss=212.1 (14.6s)\n",
      "-- Step 645, [V] eT=357.1, eL2=280.3; hT=575.6, hL2=470.0\n",
      "------108/500------\n",
      "-- Step 648, [V] eT=357.7, eL2=282.8; hT=581.2, hL2=476.5\n",
      "-- Step 648, [T] Tloss=278.8, L2loss=207.6 (9.6s)\n",
      "-- Step 651, [V*] eT=346.0, eL2=271.5; hT=559.0, hL2=459.4\n",
      "------109/500------\n",
      "-- Step 654, [V] eT=351.3, eL2=278.5; hT=570.9, hL2=469.8\n",
      "-- Step 654, [T] Tloss=283.4, L2loss=211.7 (9.9s)\n",
      "-- Step 657, [V] eT=355.0, eL2=280.1; hT=573.1, hL2=470.9\n",
      "------110/500------\n",
      "-- Step 660, [V] eT=352.4, eL2=279.9; hT=555.6, hL2=457.7\n",
      "-- Step 660, [T] Tloss=281.1, L2loss=208.8 (9.8s)\n",
      "-- Step 663, [V] eT=348.9, eL2=275.0; hT=551.2, hL2=454.4\n",
      "------111/500------\n",
      "-- Step 666, [V] eT=356.7, eL2=284.1; hT=575.5, hL2=474.1\n",
      "Decreasing lr to 0.000387\n",
      "-- Step 666, [T] Tloss=277.2, L2loss=208.2 (10.0s)\n",
      "-- Step 669, [V*] eT=345.2, eL2=273.6; hT=555.0, hL2=457.8\n",
      "------112/500------\n",
      "-- Step 672, [V] eT=350.4, eL2=278.9; hT=562.4, hL2=464.9\n",
      "-- Step 672, [T] Tloss=274.3, L2loss=207.0 (9.6s)\n",
      "-- Step 675, [V*] eT=340.3, eL2=269.3; hT=544.6, hL2=449.2\n",
      "------113/500------\n",
      "-- Step 678, [V] eT=359.2, eL2=287.5; hT=575.1, hL2=475.8\n",
      "-- Step 678, [T] Tloss=274.4, L2loss=208.3 (9.7s)\n",
      "-- Step 681, [V] eT=345.3, eL2=273.9; hT=556.3, hL2=460.0\n",
      "------114/500------\n",
      "-- Step 684, [V] eT=346.5, eL2=274.8; hT=568.2, hL2=466.5\n",
      "-- Step 684, [T] Tloss=276.7, L2loss=207.8 (9.6s)\n",
      "-- Step 687, [V] eT=344.0, eL2=273.1; hT=560.1, hL2=462.1\n",
      "------115/500------\n",
      "-- Step 690, [V] eT=347.7, eL2=277.1; hT=602.6, hL2=493.4\n",
      "Decreasing lr to 0.000349\n",
      "-- Step 690, [T] Tloss=271.5, L2loss=206.4 (9.6s)\n",
      "-- Step 693, [V] eT=347.2, eL2=276.6; hT=578.4, hL2=473.4\n",
      "------116/500------\n",
      "-- Step 696, [V*] eT=339.9, eL2=269.9; hT=571.0, hL2=469.4\n",
      "-- Step 696, [T] Tloss=266.7, L2loss=200.1 (14.4s)\n",
      "-- Step 699, [V*] eT=335.7, eL2=266.9; hT=556.7, hL2=459.7\n",
      "------117/500------\n",
      "-- Step 702, [V] eT=346.2, eL2=275.5; hT=583.8, hL2=476.5\n",
      "-- Step 702, [T] Tloss=267.8, L2loss=202.0 (9.6s)\n",
      "-- Step 705, [V] eT=341.7, eL2=272.2; hT=573.2, hL2=472.9\n",
      "------118/500------\n",
      "-- Step 708, [V] eT=339.2, eL2=270.1; hT=569.3, hL2=470.5\n",
      "-- Step 708, [T] Tloss=267.3, L2loss=202.4 (9.8s)\n",
      "-- Step 711, [V*] eT=332.2, eL2=264.2; hT=548.8, hL2=454.9\n",
      "------119/500------\n",
      "-- Step 714, [V] eT=348.5, eL2=279.1; hT=578.1, hL2=474.4\n",
      "-- Step 714, [T] Tloss=266.6, L2loss=202.6 (9.6s)\n",
      "-- Step 717, [V] eT=342.5, eL2=274.6; hT=562.5, hL2=465.9\n",
      "------120/500------\n",
      "-- Step 720, [V] eT=337.7, eL2=270.5; hT=561.3, hL2=465.4\n",
      "-- Step 720, [T] Tloss=266.5, L2loss=202.4 (9.9s)\n",
      "-- Step 723, [V] eT=339.4, eL2=271.1; hT=547.6, hL2=453.9\n",
      "------121/500------\n",
      "-- Step 726, [V] eT=342.7, eL2=275.2; hT=575.9, hL2=478.8\n",
      "Decreasing lr to 0.000314\n",
      "-- Step 726, [T] Tloss=268.1, L2loss=205.2 (9.7s)\n",
      "-- Step 729, [V] eT=339.0, eL2=271.0; hT=552.9, hL2=458.4\n",
      "------122/500------\n",
      "-- Step 732, [V*] eT=330.8, eL2=265.2; hT=556.7, hL2=464.1\n",
      "-- Step 732, [T] Tloss=269.4, L2loss=206.0 (14.3s)\n",
      "-- Step 735, [V] eT=335.0, eL2=268.8; hT=554.5, hL2=460.9\n",
      "------123/500------\n",
      "-- Step 738, [V] eT=334.4, eL2=267.8; hT=567.0, hL2=468.8\n",
      "-- Step 738, [T] Tloss=264.7, L2loss=203.1 (9.7s)\n",
      "-- Step 741, [V] eT=331.6, eL2=266.4; hT=548.5, hL2=457.4\n",
      "------124/500------\n",
      "-- Step 744, [V] eT=333.6, eL2=266.9; hT=559.6, hL2=461.7\n",
      "-- Step 744, [T] Tloss=264.5, L2loss=201.1 (9.8s)\n",
      "-- Step 747, [V] eT=336.7, eL2=270.9; hT=558.9, hL2=463.6\n",
      "Decreasing lr to 0.000282\n",
      "------125/500------\n",
      "-- Step 750, [V] eT=332.0, eL2=266.6; hT=551.5, hL2=457.8\n",
      "-- Step 750, [T] Tloss=256.0, L2loss=194.6 (9.9s)\n",
      "-- Step 753, [V*] eT=328.1, eL2=263.3; hT=553.7, hL2=459.4\n",
      "------126/500------\n",
      "-- Step 756, [V] eT=329.5, eL2=265.1; hT=545.5, hL2=453.8\n",
      "-- Step 756, [T] Tloss=257.6, L2loss=195.9 (9.7s)\n",
      "-- Step 759, [V] eT=330.8, eL2=265.5; hT=543.7, hL2=452.5\n",
      "------127/500------\n",
      "-- Step 762, [V] eT=331.8, eL2=267.1; hT=552.3, hL2=458.8\n",
      "-- Step 762, [T] Tloss=261.3, L2loss=199.8 (9.7s)\n",
      "-- Step 765, [V] eT=328.7, eL2=264.8; hT=540.1, hL2=451.2\n",
      "------128/500------\n",
      "-- Step 768, [V] eT=336.2, eL2=271.0; hT=546.9, hL2=455.2\n",
      "Decreasing lr to 0.000254\n",
      "-- Step 768, [T] Tloss=257.0, L2loss=195.8 (9.8s)\n",
      "-- Step 771, [V] eT=328.6, eL2=265.1; hT=549.8, hL2=459.1\n",
      "------129/500------\n",
      "-- Step 774, [V*] eT=327.5, eL2=263.6; hT=539.2, hL2=450.0\n",
      "-- Step 774, [T] Tloss=260.5, L2loss=198.9 (14.6s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Step 777, [V] eT=329.7, eL2=266.4; hT=547.4, hL2=456.5\n",
      "------130/500------\n",
      "-- Step 780, [V] eT=328.5, eL2=265.0; hT=538.3, hL2=449.4\n",
      "-- Step 780, [T] Tloss=256.7, L2loss=197.0 (9.7s)\n",
      "-- Step 783, [V*] eT=322.5, eL2=259.6; hT=536.6, hL2=447.8\n",
      "------131/500------\n",
      "-- Step 786, [V] eT=331.3, eL2=267.9; hT=552.6, hL2=461.0\n",
      "-- Step 786, [T] Tloss=258.4, L2loss=198.5 (9.8s)\n",
      "-- Step 789, [V] eT=328.8, eL2=265.5; hT=543.1, hL2=452.6\n",
      "------132/500------\n",
      "-- Step 792, [V] eT=325.8, eL2=263.2; hT=541.4, hL2=452.8\n",
      "-- Step 792, [T] Tloss=259.4, L2loss=199.3 (9.8s)\n",
      "-- Step 795, [V] eT=329.6, eL2=266.8; hT=548.7, hL2=457.9\n",
      "------133/500------\n",
      "-- Step 798, [V] eT=326.2, eL2=263.4; hT=552.2, hL2=459.0\n",
      "Decreasing lr to 0.000229\n",
      "-- Step 798, [T] Tloss=254.7, L2loss=196.2 (9.9s)\n",
      "-- Step 801, [V] eT=333.2, eL2=269.9; hT=560.5, hL2=465.3\n",
      "------134/500------\n",
      "-- Step 804, [V] eT=329.9, eL2=267.2; hT=559.4, hL2=466.2\n",
      "-- Step 804, [T] Tloss=257.5, L2loss=198.8 (9.8s)\n",
      "-- Step 807, [V] eT=328.8, eL2=265.8; hT=556.9, hL2=463.5\n",
      "------135/500------\n",
      "-- Step 810, [V*] eT=322.0, eL2=260.0; hT=546.2, hL2=457.0\n",
      "-- Step 810, [T] Tloss=252.1, L2loss=193.4 (14.6s)\n",
      "-- Step 813, [V] eT=330.1, eL2=266.8; hT=556.8, hL2=463.0\n",
      "------136/500------\n",
      "-- Step 816, [V] eT=329.4, eL2=266.7; hT=553.5, hL2=462.9\n",
      "-- Step 816, [T] Tloss=252.9, L2loss=193.1 (9.6s)\n",
      "-- Step 819, [V] eT=335.4, eL2=272.0; hT=567.4, hL2=470.5\n",
      "------137/500------\n",
      "-- Step 822, [V] eT=329.4, eL2=265.7; hT=560.6, hL2=465.2\n",
      "-- Step 822, [T] Tloss=253.8, L2loss=194.5 (9.8s)\n",
      "-- Step 825, [V] eT=322.6, eL2=260.9; hT=549.1, hL2=458.3\n",
      "Decreasing lr to 0.000206\n",
      "------138/500------\n",
      "-- Step 828, [V] eT=330.9, eL2=268.1; hT=552.1, hL2=460.0\n",
      "-- Step 828, [T] Tloss=251.0, L2loss=192.7 (9.6s)\n",
      "-- Step 831, [V] eT=324.1, eL2=262.9; hT=546.4, hL2=456.3\n",
      "------139/500------\n",
      "-- Step 834, [V] eT=322.3, eL2=260.5; hT=544.6, hL2=453.4\n",
      "-- Step 834, [T] Tloss=256.6, L2loss=197.6 (9.5s)\n",
      "-- Step 837, [V] eT=326.2, eL2=264.2; hT=557.6, hL2=465.5\n",
      "------140/500------\n",
      "-- Step 840, [V] eT=333.5, eL2=271.1; hT=558.2, hL2=466.0\n",
      "Decreasing lr to 0.000185\n",
      "-- Step 840, [T] Tloss=252.0, L2loss=193.6 (9.7s)\n",
      "-- Step 843, [V] eT=325.7, eL2=264.1; hT=543.6, hL2=454.9\n",
      "------141/500------\n",
      "-- Step 846, [V] eT=325.3, eL2=263.4; hT=552.3, hL2=460.8\n",
      "-- Step 846, [T] Tloss=250.6, L2loss=193.6 (9.7s)\n",
      "-- Step 849, [V*] eT=321.9, eL2=261.6; hT=548.3, hL2=458.9\n",
      "------142/500------\n",
      "-- Step 852, [V] eT=323.1, eL2=262.3; hT=545.2, hL2=457.0\n",
      "-- Step 852, [T] Tloss=250.3, L2loss=193.2 (9.6s)\n",
      "-- Step 855, [V*] eT=321.0, eL2=260.5; hT=546.4, hL2=457.9\n",
      "------143/500------\n",
      "-- Step 858, [V] eT=323.3, eL2=262.5; hT=558.3, hL2=465.9\n",
      "-- Step 858, [T] Tloss=250.9, L2loss=193.7 (9.5s)\n",
      "-- Step 861, [V] eT=323.9, eL2=263.2; hT=549.1, hL2=460.1\n",
      "------144/500------\n",
      "-- Step 864, [V] eT=328.4, eL2=266.7; hT=562.8, hL2=469.9\n",
      "-- Step 864, [T] Tloss=250.5, L2loss=193.9 (9.7s)\n",
      "-- Step 867, [V] eT=321.5, eL2=261.8; hT=539.8, hL2=453.1\n",
      "------145/500------\n",
      "-- Step 870, [V] eT=323.0, eL2=262.3; hT=560.8, hL2=467.6\n",
      "Decreasing lr to 0.000167\n",
      "-- Step 870, [T] Tloss=250.9, L2loss=194.9 (9.7s)\n",
      "-- Step 873, [V] eT=326.2, eL2=265.9; hT=549.9, hL2=460.8\n",
      "------146/500------\n",
      "-- Step 876, [V*] eT=319.2, eL2=259.4; hT=542.2, hL2=454.2\n",
      "-- Step 876, [T] Tloss=249.6, L2loss=192.5 (14.4s)\n",
      "-- Step 879, [V] eT=322.0, eL2=262.4; hT=554.5, hL2=464.2\n",
      "------147/500------\n",
      "-- Step 882, [V*] eT=317.5, eL2=257.7; hT=538.7, hL2=452.6\n",
      "-- Step 882, [T] Tloss=249.5, L2loss=192.4 (14.7s)\n",
      "-- Step 885, [V] eT=324.1, eL2=263.6; hT=551.3, hL2=460.3\n",
      "------148/500------\n",
      "-- Step 888, [V] eT=327.8, eL2=267.3; hT=546.1, hL2=457.7\n",
      "-- Step 888, [T] Tloss=248.6, L2loss=192.4 (9.6s)\n",
      "-- Step 891, [V] eT=321.1, eL2=261.8; hT=536.5, hL2=450.3\n",
      "------149/500------\n",
      "-- Step 894, [V] eT=322.2, eL2=262.5; hT=538.7, hL2=453.1\n",
      "-- Step 894, [T] Tloss=247.3, L2loss=192.4 (9.6s)\n",
      "-- Step 897, [V] eT=320.5, eL2=260.9; hT=531.4, hL2=446.4\n",
      "Decreasing lr to 0.000150\n",
      "------150/500------\n",
      "-- Step 900, [V] eT=317.9, eL2=258.7; hT=538.6, hL2=452.2\n",
      "-- Step 900, [T] Tloss=248.0, L2loss=192.8 (9.9s)\n",
      "-- Step 903, [V] eT=328.3, eL2=268.2; hT=539.0, hL2=452.6\n",
      "------151/500------\n",
      "-- Step 906, [V] eT=320.3, eL2=260.7; hT=555.0, hL2=464.1\n",
      "-- Step 906, [T] Tloss=247.2, L2loss=191.7 (9.8s)\n",
      "-- Step 909, [V] eT=322.2, eL2=262.5; hT=548.6, hL2=460.3\n",
      "------152/500------\n",
      "-- Step 912, [V] eT=322.2, eL2=262.9; hT=547.1, hL2=457.8\n",
      "Decreasing lr to 0.000135\n",
      "-- Step 912, [T] Tloss=246.4, L2loss=189.7 (9.7s)\n",
      "-- Step 915, [V] eT=319.2, eL2=260.4; hT=546.0, hL2=457.3\n",
      "------153/500------\n",
      "-- Step 918, [V*] eT=314.5, eL2=256.1; hT=550.8, hL2=461.7\n",
      "-- Step 918, [T] Tloss=248.6, L2loss=193.6 (14.4s)\n",
      "-- Step 921, [V] eT=324.3, eL2=264.8; hT=541.4, hL2=453.6\n",
      "------154/500------\n",
      "-- Step 924, [V] eT=319.9, eL2=260.7; hT=552.4, hL2=461.8\n",
      "-- Step 924, [T] Tloss=244.7, L2loss=190.2 (9.7s)\n",
      "-- Step 927, [V] eT=319.6, eL2=261.4; hT=537.6, hL2=452.6\n",
      "------155/500------\n",
      "-- Step 930, [V] eT=319.7, eL2=261.1; hT=546.9, hL2=458.0\n",
      "-- Step 930, [T] Tloss=248.5, L2loss=193.8 (9.9s)\n",
      "-- Step 933, [V] eT=316.3, eL2=257.7; hT=541.4, hL2=455.3\n",
      "Decreasing lr to 0.000122\n",
      "------156/500------\n",
      "-- Step 936, [V] eT=319.7, eL2=261.0; hT=540.3, hL2=453.7\n",
      "-- Step 936, [T] Tloss=244.9, L2loss=189.7 (9.9s)\n",
      "-- Step 939, [V*] eT=313.6, eL2=255.0; hT=545.0, hL2=457.0\n",
      "------157/500------\n",
      "-- Step 942, [V] eT=319.2, eL2=260.5; hT=540.5, hL2=453.9\n",
      "-- Step 942, [T] Tloss=247.1, L2loss=192.6 (9.6s)\n",
      "-- Step 945, [V] eT=319.1, eL2=260.7; hT=555.0, hL2=464.9\n",
      "------158/500------\n",
      "-- Step 948, [V] eT=320.1, eL2=261.4; hT=547.1, hL2=459.5\n",
      "-- Step 948, [T] Tloss=243.9, L2loss=189.5 (9.8s)\n",
      "-- Step 951, [V] eT=317.6, eL2=259.6; hT=544.7, hL2=457.4\n",
      "------159/500------\n",
      "-- Step 954, [V] eT=317.8, eL2=259.2; hT=550.7, hL2=462.7\n",
      "Decreasing lr to 0.000109\n",
      "-- Step 954, [T] Tloss=243.4, L2loss=189.5 (9.5s)\n",
      "-- Step 957, [V] eT=320.2, eL2=262.3; hT=539.6, hL2=454.1\n",
      "------160/500------\n",
      "-- Step 960, [V] eT=319.5, eL2=261.3; hT=543.7, hL2=457.3\n",
      "-- Step 960, [T] Tloss=244.7, L2loss=190.7 (9.7s)\n",
      "-- Step 963, [V] eT=314.7, eL2=257.3; hT=536.5, hL2=452.1\n",
      "------161/500------\n",
      "-- Step 966, [V] eT=316.6, eL2=258.4; hT=546.0, hL2=458.8\n",
      "-- Step 966, [T] Tloss=246.0, L2loss=191.9 (9.7s)\n",
      "-- Step 969, [V] eT=318.8, eL2=260.8; hT=541.7, hL2=455.6\n",
      "Decreasing lr to 0.000098\n",
      "------162/500------\n",
      "-- Step 972, [V] eT=321.5, eL2=263.3; hT=548.9, hL2=460.7\n",
      "-- Step 972, [T] Tloss=242.2, L2loss=188.1 (9.6s)\n",
      "-- Step 975, [V*] eT=312.4, eL2=254.7; hT=545.4, hL2=459.3\n",
      "------163/500------\n",
      "-- Step 978, [V] eT=316.8, eL2=259.2; hT=544.2, hL2=457.9\n",
      "-- Step 978, [T] Tloss=245.6, L2loss=191.4 (9.6s)\n",
      "-- Step 981, [V] eT=320.3, eL2=262.3; hT=541.7, hL2=455.8\n",
      "------164/500------\n",
      "-- Step 984, [V] eT=319.5, eL2=261.9; hT=535.4, hL2=450.8\n",
      "-- Step 984, [T] Tloss=241.6, L2loss=188.0 (9.8s)\n",
      "-- Step 987, [V] eT=314.4, eL2=257.3; hT=537.0, hL2=452.8\n",
      "------165/500------\n",
      "-- Step 990, [V] eT=314.6, eL2=257.0; hT=542.2, hL2=456.4\n",
      "Decreasing lr to 0.000089\n",
      "-- Step 990, [T] Tloss=245.4, L2loss=191.2 (9.5s)\n",
      "-- Step 993, [V] eT=320.6, eL2=262.4; hT=547.4, hL2=459.7\n",
      "------166/500------\n",
      "-- Step 996, [V] eT=318.5, eL2=261.2; hT=539.5, hL2=454.4\n",
      "-- Step 996, [T] Tloss=243.0, L2loss=189.4 (9.6s)\n",
      "-- Step 999, [V] eT=319.3, eL2=261.7; hT=541.2, hL2=455.9\n",
      "------167/500------\n",
      "-- Step 1002, [V] eT=313.2, eL2=256.4; hT=536.6, hL2=452.3\n",
      "-- Step 1002, [T] Tloss=243.1, L2loss=188.7 (9.6s)\n",
      "-- Step 1005, [V] eT=320.8, eL2=262.6; hT=549.7, hL2=461.3\n",
      "Decreasing lr to 0.000080\n",
      "------168/500------\n",
      "-- Step 1008, [V] eT=314.2, eL2=257.1; hT=543.2, hL2=456.4\n",
      "-- Step 1008, [T] Tloss=240.8, L2loss=187.7 (9.6s)\n",
      "-- Step 1011, [V] eT=320.4, eL2=263.3; hT=539.9, hL2=454.4\n",
      "------169/500------\n",
      "-- Step 1014, [V*] eT=312.3, eL2=255.6; hT=544.4, hL2=458.5\n",
      "-- Step 1014, [T] Tloss=243.7, L2loss=190.7 (14.3s)\n",
      "-- Step 1017, [V] eT=317.9, eL2=260.4; hT=543.4, hL2=457.2\n",
      "------170/500------\n",
      "-- Step 1020, [V*] eT=309.2, eL2=252.6; hT=537.7, hL2=452.9\n",
      "-- Step 1020, [T] Tloss=241.4, L2loss=188.3 (14.4s)\n",
      "-- Step 1023, [V] eT=319.8, eL2=262.1; hT=547.8, hL2=459.7\n",
      "------171/500------\n",
      "-- Step 1026, [V] eT=316.0, eL2=259.1; hT=536.8, hL2=452.2\n",
      "-- Step 1026, [T] Tloss=241.9, L2loss=188.8 (9.5s)\n",
      "-- Step 1029, [V] eT=315.4, eL2=258.0; hT=537.9, hL2=452.5\n",
      "------172/500------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Step 1032, [V] eT=314.6, eL2=257.6; hT=543.1, hL2=457.3\n",
      "-- Step 1032, [T] Tloss=244.0, L2loss=190.8 (9.6s)\n",
      "-- Step 1035, [V] eT=316.0, eL2=258.8; hT=544.3, hL2=457.9\n",
      "Decreasing lr to 0.000072\n",
      "------173/500------\n",
      "-- Step 1038, [V] eT=314.5, eL2=258.0; hT=539.8, hL2=454.8\n",
      "-- Step 1038, [T] Tloss=244.2, L2loss=191.2 (9.8s)\n",
      "-- Step 1041, [V] eT=313.6, eL2=256.9; hT=538.5, hL2=453.9\n",
      "------174/500------\n",
      "-- Step 1044, [V] eT=318.6, eL2=261.6; hT=536.1, hL2=452.4\n",
      "-- Step 1044, [T] Tloss=242.4, L2loss=189.1 (9.8s)\n",
      "-- Step 1047, [V] eT=314.7, eL2=258.5; hT=537.9, hL2=454.1\n",
      "------175/500------\n",
      "-- Step 1050, [V] eT=315.1, eL2=258.5; hT=532.0, hL2=449.1\n",
      "Decreasing lr to 0.000065\n",
      "-- Step 1050, [T] Tloss=243.6, L2loss=190.6 (9.9s)\n",
      "-- Step 1053, [V] eT=316.3, eL2=259.7; hT=534.8, hL2=452.0\n",
      "------176/500------\n",
      "-- Step 1056, [V] eT=313.4, eL2=256.7; hT=534.3, hL2=450.4\n",
      "-- Step 1056, [T] Tloss=240.4, L2loss=187.5 (9.8s)\n",
      "-- Step 1059, [V] eT=313.1, eL2=256.7; hT=535.2, hL2=451.6\n",
      "------177/500------\n",
      "-- Step 1062, [V] eT=316.1, eL2=259.5; hT=532.9, hL2=450.4\n",
      "-- Step 1062, [T] Tloss=239.4, L2loss=186.0 (9.8s)\n",
      "-- Step 1065, [V] eT=314.8, eL2=258.0; hT=541.4, hL2=456.8\n",
      "Decreasing lr to 0.000058\n",
      "------178/500------\n",
      "-- Step 1068, [V] eT=313.9, eL2=257.3; hT=537.1, hL2=453.5\n",
      "-- Step 1068, [T] Tloss=240.5, L2loss=187.6 (9.8s)\n",
      "-- Step 1071, [V] eT=313.4, eL2=257.1; hT=536.0, hL2=452.9\n",
      "Early stop at step 1071\n",
      "Finish Easy Training, 228\n"
     ]
    }
   ],
   "source": [
    "# direct to pt_ckpt\n",
    "ckpt_dir = 'pt_ckpt/'+conf.tar_model+'_'+conf.loss_combination+'/'+str(conf.ef_dim)+'/'+conf.eye+'/'\n",
    "\n",
    "train(conf, ckpt_dir, train_iter_, valid_iter_, True, False)\n",
    "\n",
    "print('Finish Easy Training, 228')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process (hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pt_ckpt/flx_l2sc/12/L/dirl_48x64_example_L170-1020\n",
      "Loading sucessfully\n",
      "------0/500------\n",
      "-- Step 0, [V*] eT=320.4, eL2=262.9; hT=539.0, hL2=453.7\n",
      "-- Step 0, [T] Tloss=275.6, L2loss=218.4 (14.5s)\n",
      "-- Step 102, [V] eT=358.7, eL2=288.2; hT=519.0, hL2=430.9\n",
      "------1/500------\n",
      "-- Step 204, [V] eT=331.7, eL2=277.7; hT=501.3, hL2=415.3\n",
      "-- Step 204, [T] Tloss=280.3, L2loss=226.4 (9.7s)\n",
      "-- Step 306, [V*] eT=282.7, eL2=245.3; hT=421.9, hL2=367.1\n",
      "------2/500------\n",
      "-- Step 408, [V*] eT=281.9, eL2=248.8; hT=411.2, hL2=360.8\n",
      "-- Step 408, [T] Tloss=241.4, L2loss=203.7 (14.4s)\n",
      "-- Step 510, [V*] eT=280.0, eL2=248.7; hT=406.0, hL2=357.6\n",
      "------3/500------\n",
      "-- Step 612, [V*] eT=276.2, eL2=246.2; hT=404.3, hL2=356.9\n",
      "-- Step 612, [T] Tloss=236.7, L2loss=203.2 (14.3s)\n",
      "-- Step 714, [V] eT=277.7, eL2=249.7; hT=399.1, hL2=353.6\n",
      "------4/500------\n",
      "-- Step 816, [V*] eT=274.2, eL2=245.8; hT=400.7, hL2=354.6\n",
      "-- Step 816, [T] Tloss=239.5, L2loss=207.2 (14.5s)\n",
      "-- Step 918, [V] eT=275.1, eL2=248.3; hT=392.7, hL2=348.7\n",
      "------5/500------\n",
      "-- Step 1020, [V*] eT=266.7, eL2=239.1; hT=390.5, hL2=344.7\n",
      "-- Step 1020, [T] Tloss=228.8, L2loss=197.8 (14.6s)\n",
      "-- Step 1122, [V] eT=273.0, eL2=246.1; hT=393.2, hL2=348.9\n",
      "------6/500------\n",
      "-- Step 1224, [V] eT=272.4, eL2=245.7; hT=393.2, hL2=348.7\n",
      "-- Step 1224, [T] Tloss=227.3, L2loss=196.7 (9.5s)\n",
      "-- Step 1326, [V] eT=268.7, eL2=243.8; hT=387.5, hL2=345.2\n",
      "------7/500------\n",
      "-- Step 1428, [V] eT=271.5, eL2=247.5; hT=388.0, hL2=347.1\n",
      "-- Step 1428, [T] Tloss=226.9, L2loss=199.6 (9.8s)\n",
      "-- Step 1530, [V*] eT=266.3, eL2=240.3; hT=389.3, hL2=345.6\n",
      "------8/500------\n",
      "-- Step 1632, [V] eT=271.4, eL2=246.0; hT=390.2, hL2=347.4\n",
      "-- Step 1632, [T] Tloss=225.3, L2loss=197.1 (9.8s)\n",
      "-- Step 1734, [V] eT=267.7, eL2=243.0; hT=384.9, hL2=341.7\n",
      "------9/500------\n",
      "-- Step 1836, [V*] eT=264.4, eL2=238.9; hT=386.2, hL2=342.6\n",
      "-- Step 1836, [T] Tloss=224.9, L2loss=195.9 (14.4s)\n",
      "-- Step 1938, [V] eT=267.9, eL2=243.9; hT=385.6, hL2=343.1\n",
      "------10/500------\n",
      "-- Step 2040, [V] eT=268.7, eL2=244.8; hT=384.6, hL2=342.3\n",
      "-- Step 2040, [T] Tloss=224.1, L2loss=195.9 (9.7s)\n",
      "-- Step 2142, [V] eT=268.9, eL2=243.7; hT=386.5, hL2=344.0\n",
      "------11/500------\n",
      "-- Step 2244, [V*] eT=262.1, eL2=237.7; hT=378.2, hL2=335.2\n",
      "-- Step 2244, [T] Tloss=222.8, L2loss=194.7 (14.3s)\n",
      "-- Step 2346, [V] eT=274.1, eL2=249.7; hT=392.2, hL2=351.9\n",
      "------12/500------\n",
      "-- Step 2448, [V] eT=270.5, eL2=249.7; hT=387.4, hL2=350.6\n",
      "-- Step 2448, [T] Tloss=222.7, L2loss=197.7 (9.8s)\n",
      "-- Step 2550, [V] eT=265.8, eL2=244.1; hT=380.2, hL2=342.9\n",
      "------13/500------\n",
      "-- Step 2652, [V] eT=271.5, eL2=249.4; hT=386.7, hL2=347.6\n",
      "-- Step 2652, [T] Tloss=217.6, L2loss=191.4 (9.8s)\n",
      "-- Step 2754, [V] eT=272.2, eL2=250.5; hT=387.5, hL2=350.4\n",
      "Decreasing lr to 0.000900\n",
      "------14/500------\n",
      "-- Step 2856, [V] eT=269.4, eL2=249.4; hT=384.8, hL2=349.8\n",
      "-- Step 2856, [T] Tloss=215.0, L2loss=191.0 (9.7s)\n",
      "-- Step 2958, [V] eT=270.6, eL2=250.4; hT=383.3, hL2=348.1\n",
      "------15/500------\n",
      "-- Step 3060, [V] eT=264.9, eL2=245.3; hT=382.5, hL2=347.7\n",
      "-- Step 3060, [T] Tloss=209.6, L2loss=185.7 (9.8s)\n",
      "-- Step 3162, [V] eT=277.9, eL2=258.4; hT=388.8, hL2=355.1\n",
      "------16/500------\n",
      "-- Step 3264, [V] eT=267.4, eL2=247.5; hT=384.3, hL2=350.6\n",
      "Decreasing lr to 0.000810\n",
      "-- Step 3264, [T] Tloss=213.0, L2loss=188.5 (9.8s)\n",
      "-- Step 3366, [V] eT=267.9, eL2=249.0; hT=384.5, hL2=350.4\n",
      "------17/500------\n",
      "-- Step 3468, [V] eT=270.8, eL2=251.7; hT=386.6, hL2=353.9\n",
      "-- Step 3468, [T] Tloss=211.2, L2loss=187.2 (9.9s)\n",
      "-- Step 3570, [V] eT=267.3, eL2=247.7; hT=380.0, hL2=345.0\n",
      "------18/500------\n",
      "-- Step 3672, [V] eT=280.7, eL2=262.3; hT=392.0, hL2=361.7\n",
      "-- Step 3672, [T] Tloss=210.2, L2loss=187.8 (9.9s)\n",
      "-- Step 3774, [V] eT=269.8, eL2=251.7; hT=383.9, hL2=352.3\n",
      "Decreasing lr to 0.000729\n",
      "------19/500------\n",
      "-- Step 3876, [V] eT=271.8, eL2=253.5; hT=385.8, hL2=354.7\n",
      "-- Step 3876, [T] Tloss=209.3, L2loss=185.9 (10.0s)\n",
      "-- Step 3978, [V] eT=265.0, eL2=245.0; hT=374.5, hL2=338.4\n",
      "Early stop at step 3978\n",
      "Finish All Training, 228\n"
     ]
    }
   ],
   "source": [
    "# direct to ckpt\n",
    "ckpt_dir = 'ckpt/'+conf.tar_model+'_'+conf.loss_combination+'/'+str(conf.ef_dim)+'/'+conf.eye+'/'\n",
    "\n",
    "train(conf, ckpt_dir, train_iter_, valid_iter_, False, True)\n",
    "\n",
    "print('Finish All Training, 228')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Training, 228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "print('Finish Training, 228\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
