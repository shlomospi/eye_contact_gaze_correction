{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import load_dataset2\n",
    "import config\n",
    "\n",
    "conf,_ = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_pose_dirs = np.asarray([d for d in os.listdir(os.path.join(conf.data_dir,conf.dataset,conf.train_dir)) if os.path.isdir(os.path.join(conf.data_dir,conf.dataset,conf.train_dir, d))])\n",
    "valid_pose_dirs = np.asarray([d for d in os.listdir(os.path.join(conf.data_dir,conf.dataset,conf.valid_dir)) if os.path.isdir(os.path.join(conf.data_dir,conf.dataset,conf.valid_dir, d))])\n",
    "print(\"[T] pose dirs\", train_pose_dirs)\n",
    "print(\"[V] pose dirs\", valid_pose_dirs)\n",
    "\n",
    "train_dicts = {}\n",
    "valid_dicts = {}\n",
    "for p in train_pose_dirs:\n",
    "    print('pose', p)\n",
    "    train_dirs = np.asarray([d for d in os.listdir(os.path.join(conf.data_dir,conf.dataset,conf.train_dir, p)) if os.path.isdir(os.path.join(conf.data_dir,conf.dataset,conf.train_dir, p, d))])\n",
    "    valid_dirs = np.asarray([d for d in os.listdir(os.path.join(conf.data_dir,conf.dataset,conf.valid_dir, p)) if os.path.isdir(os.path.join(conf.data_dir,conf.dataset,conf.valid_dir, p, d))])\n",
    "    print(\"[T] dirs\", train_dirs)\n",
    "    print(\"[V] dirs\", valid_dirs)\n",
    "\n",
    "    # load training inputs\n",
    "    train_dict = load_dataset2.load(data_dir=os.path.join(conf.data_dir,conf.dataset,conf.train_dir, p), dirs = train_dirs, eye = conf.eye)\n",
    "    # load validation inputs\n",
    "    valid_dict = load_dataset2.load(data_dir=os.path.join(conf.data_dir,conf.dataset,conf.valid_dir, p), dirs = valid_dirs, eye = conf.eye)\n",
    "\n",
    "    train_dicts[p] = train_dict\n",
    "    valid_dicts[p] = valid_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs = []\n",
    "eye_imgs = []\n",
    "lid_imgs = []\n",
    "for pose in train_dicts.keys():\n",
    "    for uid in range(len(train_dicts[pose]['imgs_ori'])):\n",
    "        for img in range(len(train_dicts[pose]['imgs_ori'][uid])):\n",
    "            ori_imgs.append(train_dicts[pose]['imgs_ori'][uid][img])\n",
    "            temp = train_dicts[pose]['imgs_ori'][uid][img]*np.tile(np.expand_dims(train_dicts[pose]['msk_eye'][uid][img], axis = 2), (1,1,3))\n",
    "            eye_imgs.append(temp)\n",
    "            temp = train_dicts[pose]['imgs_ori'][uid][img]*np.tile(np.expand_dims(train_dicts[pose]['msk_lid'][uid][img], axis = 2), (1,1,3))\n",
    "            lid_imgs.append(temp)\n",
    "            \n",
    "for pose in valid_dicts.keys():\n",
    "    for uid in range(len(valid_dicts[pose]['imgs_ori'])):\n",
    "        for img in range(len(valid_dicts[pose]['imgs_ori'][uid])):\n",
    "            ori_imgs.append(valid_dicts[pose]['imgs_ori'][uid][img])\n",
    "            temp = valid_dicts[pose]['imgs_ori'][uid][img]*np.tile(np.expand_dims(valid_dicts[pose]['msk_eye'][uid][img], axis = 2), (1,1,3))\n",
    "            eye_imgs.append(temp)\n",
    "            temp = valid_dicts[pose]['imgs_ori'][uid][img]*np.tile(np.expand_dims(valid_dicts[pose]['msk_lid'][uid][img], axis = 2), (1,1,3))\n",
    "            lid_imgs.append(temp)\n",
    "            \n",
    "ori_imgs = np.asarray(ori_imgs)\n",
    "eye_imgs = np.asarray(eye_imgs)\n",
    "lid_imgs = np.asarray(lid_imgs)\n",
    "ori_imgs = np.expand_dims(ori_imgs,axis=1)\n",
    "eye_imgs = np.expand_dims(eye_imgs,axis=1)\n",
    "lid_imgs = np.expand_dims(lid_imgs,axis=1)\n",
    "imgs = np.concatenate((ori_imgs,eye_imgs,lid_imgs), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plot(samples, filepath):\n",
    "    sample_shp = samples.shape\n",
    "    fig = plt.figure(figsize=(sample_shp[1], sample_shp[0]))\n",
    "    gs = gridspec.GridSpec(sample_shp[0], sample_shp[1])\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    samples = samples.reshape(-1, sample_shp[2], sample_shp[3], sample_shp[4])\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(sample_shp[2], sample_shp[3], sample_shp[4]))\n",
    "    plt.savefig(\"./eye_imgs/\"+str(filepath)+ \".png\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,ori_imgs.shape[0],30):\n",
    "    temp = imgs[i:i+30]\n",
    "    grid_plot(temp,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
